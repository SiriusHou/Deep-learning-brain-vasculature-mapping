{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\xhou4\\ML_CVR\\smooth8\\ML_data\\script_test\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import nibabel as nib\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../script_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\script_test'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from net_utils import unetConv2, unetUp, UnetDsv2\n",
    "import torch.nn.functional as F\n",
    "from networks_other import init_weights\n",
    "from grid_attention_layer import GridAttentionBlock2D\n",
    "\n",
    "class unet_single_att_dsv_2D(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_scale=8, n_classes=1, is_deconv=True, in_channels=1,\n",
    "                 nonlocal_mode='concatenation', attention_dsample=(2, 2), is_batchnorm=True):\n",
    "        super(unet_single_att_dsv_2D, self).__init__()\n",
    "        self.is_deconv = is_deconv\n",
    "        self.in_channels = in_channels\n",
    "        self.is_batchnorm = is_batchnorm\n",
    "        self.feature_scale = feature_scale\n",
    "\n",
    "        filters = [64, 128, 256, 512, 1024]\n",
    "        filters = [int(x / self.feature_scale) for x in filters]\n",
    "#         self.ssm_conv = nn.Sequential(nn.Conv3d(1, self.in_channels, kernel_size=(5, 3, 3),\n",
    "#                                                  stride=(1, 1, 1), padding=(0, 1, 1)),\n",
    "#                                        nn.ReLU(inplace=True),\n",
    "#                                        nn.Conv3d(self.in_channels, self.in_channels, kernel_size=(5, 3, 3),\n",
    "#                                                  stride=(1, 1, 1), padding=(0, 1, 1))\n",
    "#                                        )\n",
    "\n",
    "        # downsampling\n",
    "        self.conv1 = unetConv2(self.in_channels, filters[0], self.is_batchnorm)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv2 = unetConv2(filters[0], filters[1], self.is_batchnorm)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv3 = unetConv2(filters[1], filters[2], self.is_batchnorm)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv4 = unetConv2(filters[2], filters[3], self.is_batchnorm)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.center = unetConv2(filters[3], filters[4], self.is_batchnorm)\n",
    "        self.gating = UnetGridGatingSignal2(filters[4], filters[4], kernel_size=(1, 1), is_batchnorm=self.is_batchnorm)\n",
    "\n",
    "        # attention blocks\n",
    "        self.attentionblock2 = MultiAttentionBlock(in_size=filters[1], gate_size=filters[2], inter_size=filters[1],\n",
    "                                                   nonlocal_mode=nonlocal_mode, sub_sample_factor=attention_dsample)\n",
    "        self.attentionblock3 = MultiAttentionBlock(in_size=filters[2], gate_size=filters[3], inter_size=filters[2],\n",
    "                                                   nonlocal_mode=nonlocal_mode, sub_sample_factor=attention_dsample)\n",
    "        self.attentionblock4 = MultiAttentionBlock(in_size=filters[3], gate_size=filters[4], inter_size=filters[3],\n",
    "                                                   nonlocal_mode=nonlocal_mode, sub_sample_factor=attention_dsample)\n",
    "\n",
    "        # upsampling\n",
    "        self.up_concat4 = unetUp(filters[4], filters[3], self.is_deconv)\n",
    "        self.up_concat3 = unetUp(filters[3], filters[2], self.is_deconv)\n",
    "        self.up_concat2 = unetUp(filters[2], filters[1], self.is_deconv)\n",
    "        self.up_concat1 = unetUp(filters[1], filters[0], self.is_deconv)\n",
    "\n",
    "        # deep supervision\n",
    "        self.dsv4 = UnetDsv2(in_size=filters[3], out_size=n_classes, scale_factor=8)\n",
    "        self.dsv3 = UnetDsv2(in_size=filters[2], out_size=n_classes, scale_factor=4)\n",
    "        self.dsv2 = UnetDsv2(in_size=filters[1], out_size=n_classes, scale_factor=2)\n",
    "        self.dsv1 = nn.Conv2d(in_channels=filters[0], out_channels=n_classes, kernel_size=1)\n",
    "\n",
    "        # final conv (without any concat)\n",
    "        self.final = nn.Conv2d(n_classes*4, n_classes, 1)\n",
    "\n",
    "        # initialise weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init_weights(m, init_type='kaiming')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Slice Sequence Modeling Block\n",
    "\n",
    "#         inputs = inputs.unsqueeze(dim=1)\n",
    "#         ssm = self.ssm_conv(inputs)\n",
    "#         inputs = ssm.squeeze()\n",
    "\n",
    "#         if inputs.dim() == 3:\n",
    "#             inputs = inputs.unsqueeze(dim=0)\n",
    "\n",
    "        # Feature Extraction\n",
    "        conv1 = self.conv1(inputs)\n",
    "        maxpool1 = self.maxpool1(conv1)\n",
    "\n",
    "        conv2 = self.conv2(maxpool1)\n",
    "        maxpool2 = self.maxpool2(conv2)\n",
    "\n",
    "        conv3 = self.conv3(maxpool2)\n",
    "        maxpool3 = self.maxpool3(conv3)\n",
    "\n",
    "        conv4 = self.conv4(maxpool3)\n",
    "        maxpool4 = self.maxpool4(conv4)\n",
    "\n",
    "        # Gating Signal Generation\n",
    "        center = self.center(maxpool4)\n",
    "        gating = self.gating(center)\n",
    "\n",
    "        # Attention Mechanism\n",
    "        # Upscaling Part (Decoder)\n",
    "        g_conv4, att4 = self.attentionblock4(conv4, gating)\n",
    "        up4 = self.up_concat4(g_conv4, center)\n",
    "        g_conv3, att3 = self.attentionblock3(conv3, up4)\n",
    "        up3 = self.up_concat3(g_conv3, up4)\n",
    "        g_conv2, att2 = self.attentionblock2(conv2, up3)\n",
    "        up2 = self.up_concat2(g_conv2, up3)\n",
    "        up1 = self.up_concat1(conv1, up2)\n",
    "\n",
    "        # Deep Supervision\n",
    "        dsv4 = self.dsv4(up4)\n",
    "        dsv3 = self.dsv3(up3)\n",
    "        dsv2 = self.dsv2(up2)\n",
    "        dsv1 = self.dsv1(up1)\n",
    "        final = self.final(torch.cat([dsv1, dsv2, dsv3, dsv4], dim=1))\n",
    "\n",
    "        return final\n",
    "\n",
    "class UnetGridGatingSignal2(nn.Module):\n",
    "    def __init__(self, in_size, out_size, kernel_size=(1,1), is_batchnorm=True):\n",
    "        super(UnetGridGatingSignal2, self).__init__()\n",
    "\n",
    "        if is_batchnorm:\n",
    "            self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, kernel_size, (1,1), (0,0)),\n",
    "                                       nn.BatchNorm2d(out_size),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       )\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, kernel_size, (1,1), (0,0)),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       )\n",
    "\n",
    "        # initialise the blocks\n",
    "        for m in self.children():\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MultiAttentionBlock(nn.Module):\n",
    "    def __init__(self, in_size, gate_size, inter_size, nonlocal_mode, sub_sample_factor):\n",
    "        super(MultiAttentionBlock, self).__init__()\n",
    "        self.gate_block_1 = GridAttentionBlock2D(in_channels=in_size, gating_channels=gate_size,\n",
    "                                                 inter_channels=inter_size, mode=nonlocal_mode,\n",
    "                                                 sub_sample_factor=sub_sample_factor)\n",
    "        self.combine_gates = nn.Sequential(nn.Conv2d(in_size, in_size, kernel_size=1, stride=1, padding=0),\n",
    "                                           #nn.BatchNorm2d(in_size),\n",
    "                                           nn.ReLU(inplace=True)\n",
    "                                           )\n",
    "\n",
    "        # initialize the blocks\n",
    "        for m in self.children():\n",
    "            if m.__class__.__name__.find('GridAttentionBlock3D') != -1: continue\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, input, gating_signal):\n",
    "        gate_1, attention_1 = self.gate_block_1(input, gating_signal)\n",
    "\n",
    "        return self.combine_gates(gate_1), attention_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import nibabel as nib\n",
    "\n",
    "class CVRDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data_root):\n",
    "        'initialization'\n",
    "        self.input_IDs = []\n",
    "        self.label_IDs = []\n",
    "        'Find the file location'\n",
    "        for subname in os.listdir(data_root):\n",
    "            if os.path.isdir(os.path.join(data_root, subname)):\n",
    "                for subfile in os.listdir(os.path.join(data_root, subname)):\n",
    "                    if fnmatch.fnmatch(subfile, 'bold_mean_ws_[0]*'):\n",
    "            \n",
    "                        sub_filepath = os.path.join(data_root, subname, subfile)\n",
    "                        self.input_IDs.append(sub_filepath)\n",
    "                    \n",
    "                for tarfile in os.listdir(os.path.join(data_root, subname, 'HC')):\n",
    "                    if fnmatch.fnmatch(tarfile, 'CVR_HC_clean_[0]*'):\n",
    "                        \n",
    "                        target_filepath = os.path.join(data_root, subname, 'HC', tarfile)\n",
    "                        self.label_IDs.append(target_filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.input_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        'initialization'\n",
    "        input_x = []\n",
    "        label_y = []\n",
    "        \n",
    "        # Select input\n",
    "        input_ID = self.input_IDs[index]\n",
    "#         print(input_ID)\n",
    "        \n",
    "        # Load input\n",
    "        img = nib.load(input_ID)\n",
    "        train_image = img.get_fdata()\n",
    "        train_image = train_image.astype(np.float32)\n",
    "        img.uncache()\n",
    "        \n",
    "#         train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant', constant_values = 0) #pad zero surrounding the image\n",
    "        train_image = np.transpose(train_image, (2, 0, 1))\n",
    "        \n",
    "        A = torch.Tensor(train_image).type(torch.FloatTensor)\n",
    "        \n",
    "        # Select label\n",
    "        label_ID = self.label_IDs[index]\n",
    "#         print(label_ID)\n",
    "        \n",
    "        # Load label\n",
    "        taimg = nib.load(label_ID)\n",
    "        label_image = taimg.get_fdata()\n",
    "        label_image = label_image.astype(np.float32)\n",
    "        taimg.uncache()\n",
    "        \n",
    "#         label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant', constant_values = 0) #pad zero surrounding the image\n",
    "\n",
    "        B = torch.Tensor(label_image).type(torch.FloatTensor)\n",
    "        return [A, B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 115, 96, 112])\n",
      "torch.Size([64, 96, 112])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Generators\n",
    "training_set = CVRDataset('d:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\train')\n",
    "CVRdata = data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "\n",
    "x, y = next(iter(CVRdata))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\nn\\functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\nn\\functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1, Step [10/148], Loss: 0.1345 \n",
      "Epoch number 1, Step [20/148], Loss: 0.1055 \n",
      "Epoch number 1, Step [30/148], Loss: 0.0861 \n",
      "Epoch number 1, Step [40/148], Loss: 0.0755 \n",
      "Epoch number 1, Step [50/148], Loss: 0.0688 \n",
      "Epoch number 1, Step [60/148], Loss: 0.0605 \n",
      "Epoch number 1, Step [70/148], Loss: 0.0555 \n",
      "Epoch number 1, Step [80/148], Loss: 0.0555 \n",
      "Epoch number 1, Step [90/148], Loss: 0.0505 \n",
      "Epoch number 1, Step [100/148], Loss: 0.0474 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-616036108842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mstep_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [N, 283, H, W]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [N, H, W] with class indices (0, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e0ce61745f1c>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mtrain_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# Select label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Generators\n",
    "training_set = CVRDataset('d:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\train')\n",
    "dataloader = data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cuda: 1' if torch.cuda.is_available() else 'cpu')\n",
    "model = unet_single_att_dsv_2D(in_channels=115, n_classes=1, feature_scale=1).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "epochs = 100\n",
    "\n",
    "total_step = len(dataloader)\n",
    "loss_list = []\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    step_count = 0.0\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)  # [N, 283, H, W]\n",
    "        y = y.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "        prediction = np.squeeze(model(X))  # [N, H, W]\n",
    "\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if math.isnan(loss.item()) == False:\n",
    "            batch_loss += loss.item()\n",
    "            step_count += 1\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            running_loss += batch_loss\n",
    "            print('Epoch number {}, Step [{}/{}], Loss: {:.4f} '\n",
    "                      .format(t + 1, i + 1, total_step, loss.item()))\n",
    "            batch_loss = 0.0\n",
    "\n",
    "    loss_list.append(running_loss/step_count)\n",
    "\n",
    "## Plotting batch-wise train loss curve:\n",
    "plt.plot(loss_list, '-o', label = 'train_loss', color = 'blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_mr1_ma110116\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_mr1_ma110116\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ac033017\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ac033017\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_as061418\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_as061418\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_bm011118\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_bm011118\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_hl042519\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_hl042519\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_se082318\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_se082318\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ta011818\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ta011818\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_tw031219\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_tw031219\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1882\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1882\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1885\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1885\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1901\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1901\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1909\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1909\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1917\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1917\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1943\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1943\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1950\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1950\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1961\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1961\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1970\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1970\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1971\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1971\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2003\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2003\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2004\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2004\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2005\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2005\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2009\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2009\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2034\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2034\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2059\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2059\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2102\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2102\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2110\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2110\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2145\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2145\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2192\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2192\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2203\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2203\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2208\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2208\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2240\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2240\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2261\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2261\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2276\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2276\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2300\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2300\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2349\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2349\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2372\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2372\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2396\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2396\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2397\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2397\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2399\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2399\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2414\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2414\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2415\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2415\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2421\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2421\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2453\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2453\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2458\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2458\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2480\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2480\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2498\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2498\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2503\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2503\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2504\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2504\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2508\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2508\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2516\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2516\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2554\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2554\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2559\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2559\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2568\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2568\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2580\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2580\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2581\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2581\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2595\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2595\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2619\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2619\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2655\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2655\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2698\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2698\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2756\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2756\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2757\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2757\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2873\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2873\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2911\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2911\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2957\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2957\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2975\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2975\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2976\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2976\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2989\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2989\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2993\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2993\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3004\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3004\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3005\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3005\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3014\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3014\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3053\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3053\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3082\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3082\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3187\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3187\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3248\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3248\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3277\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3277\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3337\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3337\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3352\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3352\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9269\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9269\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9303\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9303\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9621\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9621\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9685\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9685\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9703\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9703\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9982\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9982\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2206\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2206\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2219\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2219\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2220\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2220\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2229\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2229\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2230\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2230\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2306\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2306\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2326\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2326\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2337\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2337\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2358\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2358\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2359\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2359\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2417\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2417\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2418\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2418\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2588\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2588\\HC/CVR_HC_clean.nii\n"
     ]
    }
   ],
   "source": [
    "test_dir = 'd:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\test'\n",
    "os.chdir(test_dir)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for subname in glob.glob('*\\\\'):\n",
    "        test_result = np.zeros((96, 112, 91))\n",
    "\n",
    "        tensor_x = []\n",
    "        tensor_y = []\n",
    "\n",
    "        sub_filename = os.path.join(test_dir, subname, 'bold_corr_rp_c.nii')\n",
    "        print(sub_filename)\n",
    "        img = nib.load(sub_filename)\n",
    "        img_data = img.get_fdata()\n",
    "        img.uncache()\n",
    "\n",
    "        for i in range(80):\n",
    "            train_image = np.squeeze(img_data[:, :, i, :])\n",
    "            train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant') #pad zero surrounding the image\n",
    "            train_image = np.transpose(train_image, (2, 0, 1))\n",
    "            tensor_x.append(torch.Tensor(train_image))\n",
    "\n",
    "        target_filename = os.path.join(test_dir, subname, 'HC/CVR_HC_clean.nii')\n",
    "        print(target_filename)\n",
    "        taimg = nib.load(target_filename)\n",
    "        taimg_data = taimg.get_fdata()    \n",
    "        taimg.uncache()\n",
    "\n",
    "        for i in range(80):\n",
    "            label_image = np.squeeze(taimg_data[:, :, i])\n",
    "            label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant') #pad zero surrounding the image\n",
    "            tensor_y.append(torch.Tensor(label_image))\n",
    "\n",
    "        tensor_x_stacked = torch.stack(tensor_x)\n",
    "        tensor_y_stacked = torch.stack(tensor_y)\n",
    "\n",
    "        test_data = torch.utils.data.TensorDataset(tensor_x_stacked,tensor_y_stacked)\n",
    "        testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=1)\n",
    "\n",
    "        i = 0\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "        #         plt.imshow(X[0][1]) \n",
    "        #         plt.show()\n",
    "            outputs = np.squeeze(model(X).cpu().clone().numpy())\n",
    "            test_result[:, :, i] = outputs\n",
    "            i += 1\n",
    "\n",
    "        img_output = nib.Nifti1Image(test_result, taimg.affine)\n",
    "        img_output.get_data_dtype() == np.dtype(np.int16)\n",
    "        nib.save(img_output, os.path.join(test_dir, subname, 'ML_result_aUnet_XYZ.nii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'd:/xhou4/ML_CVR/smooth8/ML_data/AUnet_train_model_norm_XYZ_135sub.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_py3_xh",
   "language": "python",
   "name": "py3_xh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
