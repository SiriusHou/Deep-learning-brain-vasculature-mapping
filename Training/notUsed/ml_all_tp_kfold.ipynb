{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://discuss.pytorch.org/t/unet-implementation/426\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        up_mode='upconv',\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(prev_channels, n_classes, kernel_size=1),\n",
    "            nn.Tanh())            \n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import nibabel as nib\n",
    "\n",
    "class CVRDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data_root):\n",
    "        'initialization'\n",
    "        self.input_IDs = []\n",
    "        self.label_IDs = []\n",
    "        'Find the file location'\n",
    "        for subname in os.listdir(data_root):\n",
    "            if os.path.isdir(os.path.join(data_root, subname)):\n",
    "#                 print(subname)      \n",
    "                sub_filepath = os.path.join(data_root, subname, 'bold_corr_rp_c.nii')\n",
    "#                 print(sub_filepath)\n",
    "                self.input_IDs.append(sub_filepath)\n",
    "\n",
    "                target_filepath = os.path.join(data_root, subname, 'HC\\\\CVR_HC_clean.nii')\n",
    "#                 print(target_filepath)\n",
    "                self.label_IDs.append(target_filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.input_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        'initialization'\n",
    "        input_x = []\n",
    "        label_y = []\n",
    "        \n",
    "        # Select input\n",
    "        input_ID = self.input_IDs[index]\n",
    "        print(input_ID)\n",
    "        \n",
    "        # Load input\n",
    "        img = nib.load(input_ID)\n",
    "        img_data = img.get_fdata()\n",
    "        img_data = img_data.astype(np.float32)\n",
    "        img.uncache()\n",
    "        \n",
    "        for i in range(10, 70):\n",
    "            train_image = np.squeeze(img_data[:, :, i, :])\n",
    "            train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant') #pad zero surrounding the image\n",
    "            train_image = np.transpose(train_image, (2, 0, 1))\n",
    "            input_x.append(train_image)\n",
    "        \n",
    "        A = torch.Tensor(input_x).type(torch.FloatTensor)\n",
    "        \n",
    "        # Select label\n",
    "        label_ID = self.label_IDs[index]\n",
    "        print(label_ID)\n",
    "        \n",
    "        # Load label\n",
    "        taimg = nib.load(label_ID)\n",
    "        taimg_data = taimg.get_fdata()\n",
    "        taimg_data = taimg_data.astype(np.float32)\n",
    "        taimg.uncache()\n",
    "        \n",
    "        for i in range(10, 70):\n",
    "            label_image = np.squeeze(taimg_data[:, :, i])\n",
    "            label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant') #pad zero surrounding the image\n",
    "            label_y.append(label_image)\n",
    "        \n",
    "        B = torch.Tensor(label_y).type(torch.FloatTensor)\n",
    "        return [A, B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CVRDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-47db595520d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtraining_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCVRDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mCVRdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CVRDataset' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Generators\n",
    "training_set = CVRDataset('d:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\train')\n",
    "CVRdata = data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "\n",
    "# x, y = next(iter(CVRdata))\n",
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1502\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1502\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1858\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1858\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1443\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1443\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1038\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1038\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1368\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1368\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T0935\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T0935\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb2931\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb2931\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1322\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1322\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1395\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1395\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1381\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1381\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\hlu_xmr_tt072717\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\hlu_xmr_tt072717\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1782\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1782\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1696\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1696\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1630\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1630\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\HLu_DC_MR1_10102016\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\HLu_DC_MR1_10102016\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\hlu_mr1_ns031418\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\hlu_mr1_ns031418\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1147\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1147\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb5264\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb5264\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb3188\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb3188\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1246\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1246\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb3683\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb3683\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1559\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1559\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1533\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1533\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1175\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1175\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1819\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1819\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1117\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1117\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1100\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1100\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1048\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1048\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1562\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1562\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1382\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1382\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1571\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1571\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1857\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1857\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1228\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1228\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3TB5706\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3TB5706\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T0922\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T0922\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1556\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1556\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1648\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1648\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1369\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1369\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\HLu_DC_MR1_07232016\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\HLu_DC_MR1_07232016\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1156\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1156\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb3239\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3tb3239\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1861\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1861\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1881\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1881\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1628\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1628\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1812\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1812\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\hlu_mr1_vl031519\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\hlu_mr1_vl031519\\HC\\CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\train\\3T1444\\bold_corr_rp_c.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-44-b0b2791a9e8c>\", line 8, in <module>\n",
      "    x, y = next(iter(CVRdata))\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 346, in __next__\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"<ipython-input-43-5f9312dbce12>\", line 50, in __getitem__\n",
      "    A = torch.Tensor(input_x).type(torch.FloatTensor)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3322, in run_code\n",
      "    sys.excepthook = old_excepthook\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 173, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Windows\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3318\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3319\u001b[1;33m                     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3320\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-b0b2791a9e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCVRdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-5f9312dbce12>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3321\u001b[0m                 \u001b[1;31m# Reset our crash handler in place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3322\u001b[1;33m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexcepthook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_excepthook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3323\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2033\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2034\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2035\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3334\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3335\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3336\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3337\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3338\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2035\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2037\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1418\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1316\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1318\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1319\u001b[0m             )\n\u001b[0;32m   1320\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Generators\n",
    "training_set = CVRDataset('d:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\train')\n",
    "CVRdata = data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "\n",
    "x, y = next(iter(CVRdata))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a087f59da9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mstep_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [N, 6, H, W]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [N, H, W] with class indices (0, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-22fb5d75b6a8>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mimg_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mimg_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muncache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "\n",
    "# Generators\n",
    "training_set = CVRDataset('d:/xhou4/ML_CVR/smooth8/ML_data/train')\n",
    "dataloader = data.DataLoader(training_set, **params)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=283, n_classes=1, depth = 5, padding=True, up_mode='upconv').to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "epochs = 100\n",
    "\n",
    "total_step = len(dataloader)\n",
    "loss_list = []\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    step_count = 0.0\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)  # [N, 6, H, W]\n",
    "        y = y.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "#         prediction = np.squeeze(model(X))  # [N, H, W]\n",
    "\n",
    "#         loss = criterion(prediction, y)\n",
    "\n",
    "#         optim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "\n",
    "#         if math.isnan(loss.item()) == False:\n",
    "#             batch_loss += loss.item()\n",
    "#             step_count += 1\n",
    "\n",
    "#         if (i + 1) % 10 == 0:\n",
    "#             running_loss += batch_loss\n",
    "#             print('Epoch number {}, Step [{}/{}], Loss: {:.4f} '\n",
    "#                       .format(t + 1, i + 1, total_step, loss.item()))\n",
    "#             batch_loss = 0.0\n",
    "\n",
    "#     loss_list.append(running_loss/step_count)\n",
    "\n",
    "# ## Plotting batch-wise train loss curve:\n",
    "# plt.plot(loss_list, '-o', label = 'train_loss', color = 'blue')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_dir = 'd:/xhou4/ML_CVR/smooth8/ML_data/train'\n",
    "os.chdir(train_dir)\n",
    "\n",
    "tensor_x = []\n",
    "tensor_y = []\n",
    "for subname in glob.glob('*/'):\n",
    "    print(subname)      \n",
    "    sub_filename = os.path.join(train_dir, subname, 'bold_corr_rp_c.nii')\n",
    "    img = nib.load(sub_filename)\n",
    "    img_data = img.get_fdata()\n",
    "    img.uncache()\n",
    "\n",
    "    for i in range(10, 70):\n",
    "        train_image = np.squeeze(img_data[:, :, i, :])\n",
    "        train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant') #pad zero surrounding the image\n",
    "        train_image = np.transpose(train_image, (2, 0, 1))\n",
    "        tensor_x.append(torch.Tensor(train_image))\n",
    "\n",
    "    target_filename = os.path.join(train_dir, subname, 'HC/CVR_HC_clean.nii')\n",
    "    print(target_filename)\n",
    "    taimg = nib.load(target_filename)\n",
    "    taimg_data = taimg.get_fdata()    \n",
    "    taimg.uncache()\n",
    "\n",
    "    for i in range(10, 70):\n",
    "        label_image = np.squeeze(taimg_data[:, :, i])\n",
    "        label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant') #pad zero surrounding the image\n",
    "        tensor_y.append(torch.Tensor(label_image))\n",
    "\n",
    "    tensor_x_stacked = torch.stack(tensor_x)\n",
    "    tensor_y_stacked = torch.stack(tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3T1766\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1766\\HC/CVR_HC_clean.nii\n",
      "3T1782\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1782\\HC/CVR_HC_clean.nii\n",
      "3T1786\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1786\\HC/CVR_HC_clean.nii\n",
      "3T1812\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1812\\HC/CVR_HC_clean.nii\n",
      "3T1818\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1818\\HC/CVR_HC_clean.nii\n",
      "3T1819\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1819\\HC/CVR_HC_clean.nii\n",
      "3T1820\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1820\\HC/CVR_HC_clean.nii\n",
      "3T1826\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1826\\HC/CVR_HC_clean.nii\n",
      "3T1838\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1838\\HC/CVR_HC_clean.nii\n",
      "3T1857\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1857\\HC/CVR_HC_clean.nii\n",
      "3T1858\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1858\\HC/CVR_HC_clean.nii\n",
      "3T1859\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1859\\HC/CVR_HC_clean.nii\n",
      "3T1861\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1861\\HC/CVR_HC_clean.nii\n",
      "3T1872\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1872\\HC/CVR_HC_clean.nii\n",
      "3T1880\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1880\\HC/CVR_HC_clean.nii\n",
      "3T1881\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1881\\HC/CVR_HC_clean.nii\n",
      "3T0807\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0807\\HC/CVR_HC_clean.nii\n",
      "3T0902\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0902\\HC/CVR_HC_clean.nii\n",
      "3T0921\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0921\\HC/CVR_HC_clean.nii\n",
      "3T0922\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0922\\HC/CVR_HC_clean.nii\n",
      "3T0935\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0935\\HC/CVR_HC_clean.nii\n",
      "3T0938\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0938\\HC/CVR_HC_clean.nii\n",
      "3T0944\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0944\\HC/CVR_HC_clean.nii\n",
      "3T0947\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0947\\HC/CVR_HC_clean.nii\n",
      "3T0955\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0955\\HC/CVR_HC_clean.nii\n",
      "3T0990\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T0990\\HC/CVR_HC_clean.nii\n",
      "3T1038\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1038\\HC/CVR_HC_clean.nii\n",
      "3T1048\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1048\\HC/CVR_HC_clean.nii\n",
      "3T1063\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1063\\HC/CVR_HC_clean.nii\n",
      "3T1073\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1073\\HC/CVR_HC_clean.nii\n",
      "3T1074\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1074\\HC/CVR_HC_clean.nii\n",
      "3T1100\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1100\\HC/CVR_HC_clean.nii\n",
      "3T1104\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1104\\HC/CVR_HC_clean.nii\n",
      "3T1117\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1117\\HC/CVR_HC_clean.nii\n",
      "3T1129\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1129\\HC/CVR_HC_clean.nii\n",
      "3T1130\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1130\\HC/CVR_HC_clean.nii\n",
      "3T1147\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1147\\HC/CVR_HC_clean.nii\n",
      "3T1156\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1156\\HC/CVR_HC_clean.nii\n",
      "3T1175\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1175\\HC/CVR_HC_clean.nii\n",
      "3T1189\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1189\\HC/CVR_HC_clean.nii\n",
      "3T1208\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1208\\HC/CVR_HC_clean.nii\n",
      "3T1209\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1209\\HC/CVR_HC_clean.nii\n",
      "3T1227\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1227\\HC/CVR_HC_clean.nii\n",
      "3T1228\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1228\\HC/CVR_HC_clean.nii\n",
      "3T1246\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1246\\HC/CVR_HC_clean.nii\n",
      "3T1257\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1257\\HC/CVR_HC_clean.nii\n",
      "3T1273\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1273\\HC/CVR_HC_clean.nii\n",
      "3T1281\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1281\\HC/CVR_HC_clean.nii\n",
      "3T1322\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1322\\HC/CVR_HC_clean.nii\n",
      "3T1331\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1331\\HC/CVR_HC_clean.nii\n",
      "3T1338\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1338\\HC/CVR_HC_clean.nii\n",
      "3T1339\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1339\\HC/CVR_HC_clean.nii\n",
      "3T1365\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1365\\HC/CVR_HC_clean.nii\n",
      "3T1368\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1368\\HC/CVR_HC_clean.nii\n",
      "3T1369\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1369\\HC/CVR_HC_clean.nii\n",
      "3T1377\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1377\\HC/CVR_HC_clean.nii\n",
      "3T1381\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1381\\HC/CVR_HC_clean.nii\n",
      "3T1382\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1382\\HC/CVR_HC_clean.nii\n",
      "3T1395\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1395\\HC/CVR_HC_clean.nii\n",
      "3T1437\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1437\\HC/CVR_HC_clean.nii\n",
      "3T1438\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1438\\HC/CVR_HC_clean.nii\n",
      "3T1442\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1442\\HC/CVR_HC_clean.nii\n",
      "3T1443\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1443\\HC/CVR_HC_clean.nii\n",
      "3T1444\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1444\\HC/CVR_HC_clean.nii\n",
      "3T1455\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1455\\HC/CVR_HC_clean.nii\n",
      "3T1466\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1466\\HC/CVR_HC_clean.nii\n",
      "3T1470\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1470\\HC/CVR_HC_clean.nii\n",
      "3T1472\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1472\\HC/CVR_HC_clean.nii\n",
      "3T1473\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1473\\HC/CVR_HC_clean.nii\n",
      "3T1477\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1477\\HC/CVR_HC_clean.nii\n",
      "3T1478\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1478\\HC/CVR_HC_clean.nii\n",
      "3T1494\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1494\\HC/CVR_HC_clean.nii\n",
      "3T1502\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1502\\HC/CVR_HC_clean.nii\n",
      "3T1521\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1521\\HC/CVR_HC_clean.nii\n",
      "3T1533\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1533\\HC/CVR_HC_clean.nii\n",
      "3T1549\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1549\\HC/CVR_HC_clean.nii\n",
      "3T1556\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1556\\HC/CVR_HC_clean.nii\n",
      "3T1557\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1557\\HC/CVR_HC_clean.nii\n",
      "3T1558\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1558\\HC/CVR_HC_clean.nii\n",
      "3T1559\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1559\\HC/CVR_HC_clean.nii\n",
      "3T1562\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1562\\HC/CVR_HC_clean.nii\n",
      "3T1570\\\n",
      "d:/xhou4/ML_CVR/smooth8/ML_data/train\\3T1570\\HC/CVR_HC_clean.nii\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2f3273980a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mtensor_x_stacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtensor_y_stacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtsensor_x_stacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_dir = 'd:/xhou4/ML_CVR/smooth8/ML_data/train'\n",
    "os.chdir(train_dir)\n",
    "\n",
    "tensor_x = []\n",
    "tensor_y = []\n",
    "for subname in glob.glob('*/'):\n",
    "    print(subname)      \n",
    "    sub_filename = os.path.join(train_dir, subname, 'bold_corr_rp_c.nii')\n",
    "    img = nib.load(sub_filename)\n",
    "    img_data = img.get_fdata()\n",
    "    img.uncache()\n",
    "\n",
    "    for i in range(10, 70):\n",
    "        train_image = np.squeeze(img_data[:, :, i, :])\n",
    "        train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant') #pad zero surrounding the image\n",
    "        train_image = np.transpose(train_image, (2, 0, 1))\n",
    "        tensor_x.append(torch.Tensor(train_image))\n",
    "\n",
    "    target_filename = os.path.join(train_dir, subname, 'HC/CVR_HC_clean.nii')\n",
    "    print(target_filename)\n",
    "    taimg = nib.load(target_filename)\n",
    "    taimg_data = taimg.get_fdata()    \n",
    "    taimg.uncache()\n",
    "\n",
    "    for i in range(10, 70):\n",
    "        label_image = np.squeeze(taimg_data[:, :, i])\n",
    "        label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant') #pad zero surrounding the image\n",
    "        tensor_y.append(torch.Tensor(label_image))\n",
    "\n",
    "    tensor_x_stacked = torch.stack(tensor_x)\n",
    "    tensor_y_stacked = torch.stack(tensor_y)\n",
    "\n",
    "print(tensor_x_stacked.shape)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(tensor_x_stacked,tensor_y_stacked)\n",
    "dataloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=64)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=283, n_classes=1, depth = 5, padding=True, up_mode='upconv').to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "epochs = 100\n",
    "\n",
    "total_step = len(dataloader)\n",
    "loss_list = []\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    step_count = 0.0\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        X = X.to(device)  # [N, 6, H, W]\n",
    "        y = y.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "        prediction = np.squeeze(model(X))  # [N, H, W]\n",
    "\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if math.isnan(loss.item()) == False:\n",
    "            batch_loss += loss.item()\n",
    "            step_count += 1\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            running_loss += batch_loss\n",
    "            print('Epoch number {}, Step [{}/{}], Loss: {:.4f} '\n",
    "                      .format(t + 1, i + 1, total_step, loss.item()))\n",
    "            batch_loss = 0.0\n",
    "\n",
    "    loss_list.append(running_loss/step_count)\n",
    "\n",
    "## Plotting batch-wise train loss curve:\n",
    "plt.plot(loss_list, '-o', label = 'train_loss', color = 'blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'd:/xhou4/ML_CVR/dataMixed/data/data/corr_eff'\n",
    "os.chdir(test_dir)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "for subname in glob.glob('3T*/'):\n",
    "    if subname == subname_p:\n",
    "        test_result = np.zeros((96, 112, 91))\n",
    "\n",
    "        tensor_x = []\n",
    "        tensor_y = []\n",
    "\n",
    "        sub_filename = os.path.join(test_dir, subname, 'bold_corr_eff.nii')\n",
    "        print(sub_filename)\n",
    "        img = nib.load(sub_filename)\n",
    "        img_data = img.get_fdata()\n",
    "        img.uncache()\n",
    "\n",
    "        for i in range(80):\n",
    "            train_image = np.squeeze(img_data[:, :, i, :])\n",
    "            train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant') #pad zero surrounding the image\n",
    "            train_image = np.transpose(train_image, (2, 0, 1))\n",
    "            tensor_x.append(torch.Tensor(train_image))\n",
    "\n",
    "        target_filename = os.path.join(test_dir, subname, 'HC/CVR_HC_clean.img')\n",
    "        print(target_filename)\n",
    "        taimg = nib.load(target_filename)\n",
    "        taimg_data = taimg.get_fdata()    \n",
    "        taimg.uncache()\n",
    "\n",
    "        for i in range(80):\n",
    "            label_image = np.squeeze(taimg_data[:, :, i])\n",
    "            label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant') #pad zero surrounding the image\n",
    "            tensor_y.append(torch.Tensor(label_image))\n",
    "\n",
    "        tensor_x_stacked = torch.stack(tensor_x)\n",
    "        tensor_y_stacked = torch.stack(tensor_y)\n",
    "\n",
    "        test_data = torch.utils.data.TensorDataset(tensor_x_stacked,tensor_y_stacked)\n",
    "        testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=1)\n",
    "\n",
    "        i = 0\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "        #         plt.imshow(X[0][1]) \n",
    "        #         plt.show()\n",
    "            outputs = np.squeeze(model(X).cpu().clone().numpy())\n",
    "            test_result[:, :, i] = 2* outputs + 0.5\n",
    "            i += 1\n",
    "\n",
    "        img_output = nib.Nifti1Image(test_result, taimg.affine)\n",
    "        img_output.get_data_dtype() == np.dtype(np.int16)\n",
    "        nib.save(img_output, os.path.join(test_dir, subname, 'ML_trained_corr_eff_Kfold.nii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_py3_xh",
   "language": "python",
   "name": "py3_xh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
