{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\script_test\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import nibabel as nib\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\script_test'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://discuss.pytorch.org/t/unet-implementation/426\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        up_mode='upconv',\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(prev_channels, n_classes, kernel_size=1),\n",
    "            nn.Tanh())            \n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import nibabel as nib\n",
    "\n",
    "class CVRDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data_root):\n",
    "        'initialization'\n",
    "        self.input_IDs = []\n",
    "        self.label_IDs = []\n",
    "        'Find the file location'\n",
    "        for subname in os.listdir(data_root):\n",
    "            if os.path.isdir(os.path.join(data_root, subname)):\n",
    "                for subfile in os.listdir(os.path.join(data_root, subname)):\n",
    "                    if fnmatch.fnmatch(subfile, 'bold_corr_0*'):\n",
    "            \n",
    "                        sub_filepath = os.path.join(data_root, subname, subfile)\n",
    "                        self.input_IDs.append(sub_filepath)\n",
    "                    \n",
    "                for tarfile in os.listdir(os.path.join(data_root, subname, 'HC')):\n",
    "                    if fnmatch.fnmatch(tarfile, 'CVR_HC_clean_0*'):\n",
    "                        \n",
    "                        target_filepath = os.path.join(data_root, subname, 'HC', tarfile)\n",
    "                        self.label_IDs.append(target_filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.input_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        'initialization'\n",
    "        input_x = []\n",
    "        label_y = []\n",
    "\n",
    "        # Select input\n",
    "        input_ID = self.input_IDs[index]\n",
    "#         print(input_ID)\n",
    "        \n",
    "        # Load input\n",
    "        img = nib.load(input_ID)\n",
    "        train_image = img.get_fdata()\n",
    "        train_image = train_image.astype(np.float32)\n",
    "#         img.uncache()\n",
    "\n",
    "#         train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant') #pad zero surrounding the image\n",
    "        train_image = np.transpose(train_image, (2, 0, 1))\n",
    "        \n",
    "        A = torch.Tensor(train_image).type(torch.FloatTensor)\n",
    "        \n",
    "        # Select label\n",
    "        label_ID = self.label_IDs[index]\n",
    "#         print(label_ID)\n",
    "        \n",
    "        # Load label\n",
    "        taimg = nib.load(label_ID)\n",
    "        label_image = taimg.get_fdata()\n",
    "        label_image = label_image.astype(np.float32)\n",
    "#         taimg.uncache()\n",
    "        \n",
    "#         label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant') #pad zero surrounding the image\n",
    "\n",
    "        B = torch.Tensor(label_image).type(torch.FloatTensor)\n",
    "        return [A, B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-3f87fc5a720a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mCVRdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCVRdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generators\n",
    "    training_set = CVRDataset('d:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\train')\n",
    "    CVRdata = data.DataLoader(training_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "    x, y = next(iter(CVRdata))\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1, Step [10/119], Training Loss: 0.0769 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-06ead04d66f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [N, 6, H, W]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [N, H, W] with class indices (0, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-9eac36388c7b>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Load input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtrain_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mtrain_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muncache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\nibabel\\dataobj_images.py\u001b[0m in \u001b[0;36mget_fdata\u001b[1;34m(self, caching, dtype)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;31m# For array proxies, will attempt to confine data array to dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;31m# during scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fill'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\nibabel\\arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[0mScaled\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \"\"\"\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scaled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslicer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Lulab\\hfan11\\Anaconda3\\envs\\py3_xh\\lib\\site-packages\\nibabel\\arrayproxy.py\u001b[0m in \u001b[0;36m_get_scaled\u001b[1;34m(self, dtype, slicer)\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_unscaled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscl_slope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscl_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpromote_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "validation_split = 0.2\n",
    "random_seed = 42\n",
    "shuffle_dataset = True\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "training_set_size = len(training_set)\n",
    "indices = list(range(training_set_size))\n",
    "split = int(np.floor(validation_split * training_set_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Generators\n",
    "training_set = CVRDataset('d:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\train')\n",
    "train_loader = data.DataLoader(training_set, batch_size=64, sampler=train_sampler, num_workers=2)\n",
    "validation_loader = data.DataLoader(training_set, batch_size=64, sampler=valid_sampler, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=283, n_classes=1, depth = 5, padding=True, up_mode='upconv').to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "epochs = 2\n",
    "print_every = 10\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    step_count = 0.0\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_total_loss = 0.0\n",
    "    test_step_count = 0.0\n",
    "    \n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X = X.to(device)  # [N, 6, H, W]\n",
    "        y = y.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "        prediction = np.squeeze(model(X))  # [N, H, W]\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if math.isnan(loss.item()) == False:\n",
    "            train_loss += loss.item()\n",
    "            step_count += 1\n",
    "\n",
    "        if (i + 1) % print_every == 0:\n",
    "            running_loss += train_loss\n",
    "            print('Epoch number {}, Step [{}/{}], Training Loss: {:.4f} '\n",
    "                      .format(t + 1, i + 1, total_step, loss.item()))\n",
    "            train_loss = 0.0\n",
    "        \n",
    "            #validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for X, y in validation_loader:\n",
    "                    X = X.to(device)  # [N, 6, H, W]\n",
    "                    y = y.to(device)  # [N, H, W] with class indices (0, 1)    \n",
    "                    prediction = np.squeeze(model(X))  # [N, H, W]\n",
    "                    loss = criterion(prediction, y)\n",
    "                    \n",
    "                    if math.isnan(loss.item()) == False:\n",
    "                        test_loss = loss.item()\n",
    "                        test_step_count += 1\n",
    "\n",
    "                    test_total_loss += test_loss   \n",
    "                    test_loss = 0\n",
    "                    \n",
    "    test_loss_list.append(test_total_loss/test_step_count)        \n",
    "    train_loss_list.append(running_loss/step_count)\n",
    "    \n",
    "## Plotting batch-wise train loss curve:\n",
    "plt.plot(train_loss_list, '-o', label = 'train_loss', color = 'blue')\n",
    "plt.plot(test_loss_list, '-o', label = 'test_loss', color = 'orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_mr1_ma110116\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_mr1_ma110116\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ac033017\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ac033017\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_as061418\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_as061418\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_bm011118\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_bm011118\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_hl042519\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_hl042519\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_se082318\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_se082318\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ta011818\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_ta011818\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_tw031219\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\hlu_xmr_tw031219\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1882\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1882\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1885\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1885\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1901\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1901\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1909\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1909\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1917\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1917\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1943\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1943\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1950\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1950\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1961\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1961\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1970\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1970\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1971\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T1971\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2003\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2003\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2004\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2004\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2005\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2005\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2009\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2009\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2034\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2034\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2059\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2059\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2102\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2102\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2110\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2110\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2145\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2145\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2192\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2192\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2203\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2203\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2208\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2208\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2240\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2240\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2261\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2261\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2276\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2276\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2300\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2300\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2349\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2349\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2372\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2372\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2396\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2396\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2397\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2397\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2399\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2399\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2414\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2414\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2415\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2415\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2421\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2421\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2453\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2453\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2458\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2458\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2480\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2480\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2498\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2498\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2503\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2503\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2504\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2504\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2508\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2508\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2516\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2516\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2554\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2554\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2559\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2559\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2568\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2568\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2580\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2580\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2581\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2581\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2595\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2595\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2619\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2619\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2655\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2655\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2698\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2698\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2756\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2756\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2757\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2757\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2873\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2873\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2911\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2911\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2957\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2957\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2975\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2975\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2976\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2976\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2989\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2989\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2993\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T2993\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3004\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3004\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3005\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3005\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3014\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3014\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3053\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3053\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3082\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3082\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3187\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3187\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3248\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3248\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3277\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3277\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3337\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3337\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3352\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T3352\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9269\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9269\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9303\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9303\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9621\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9621\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9685\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9685\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9703\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9703\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9982\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3T9982\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2206\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2206\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2219\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2219\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2220\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2220\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2229\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2229\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2230\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2230\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2306\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2306\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2326\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2326\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2337\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2337\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2358\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2358\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2359\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2359\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2417\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2417\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2418\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3TB2418\\HC/CVR_HC_clean.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2588\\bold_corr_rp_c.nii\n",
      "d:\\xhou4\\ML_CVR\\smooth8\\ML_data\\test\\3tb2588\\HC/CVR_HC_clean.nii\n"
     ]
    }
   ],
   "source": [
    "test_dir = 'd:\\\\xhou4\\\\ML_CVR\\\\smooth8\\\\ML_data\\\\test'\n",
    "os.chdir(test_dir)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for subname in glob.glob('*\\\\'):\n",
    "        test_result = np.zeros((96, 112, 91))\n",
    "\n",
    "        tensor_x = []\n",
    "        tensor_y = []\n",
    "\n",
    "        sub_filename = os.path.join(test_dir, subname, 'bold_corr_rp_c.nii')\n",
    "        print(sub_filename)\n",
    "        img = nib.load(sub_filename)\n",
    "        img_data = img.get_fdata()\n",
    "        img.uncache()\n",
    "\n",
    "        for i in range(80):\n",
    "            train_image = np.squeeze(img_data[:, :, i, :])\n",
    "            train_image = np.pad(train_image, ((2, 3), (1, 2), (0, 0)), 'constant') #pad zero surrounding the image\n",
    "            train_image = np.transpose(train_image, (2, 0, 1))\n",
    "            tensor_x.append(torch.Tensor(train_image))\n",
    "\n",
    "        target_filename = os.path.join(test_dir, subname, 'HC/CVR_HC_clean.nii')\n",
    "        print(target_filename)\n",
    "        taimg = nib.load(target_filename)\n",
    "        taimg_data = taimg.get_fdata()    \n",
    "        taimg.uncache()\n",
    "\n",
    "        for i in range(80):\n",
    "            label_image = np.squeeze(taimg_data[:, :, i])\n",
    "            label_image = np.pad(label_image, ((2, 3), (1, 2)), 'constant') #pad zero surrounding the image\n",
    "            tensor_y.append(torch.Tensor(label_image))\n",
    "\n",
    "        tensor_x_stacked = torch.stack(tensor_x)\n",
    "        tensor_y_stacked = torch.stack(tensor_y)\n",
    "\n",
    "        test_data = torch.utils.data.TensorDataset(tensor_x_stacked,tensor_y_stacked)\n",
    "        testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=1)\n",
    "\n",
    "        i = 0\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "        #         plt.imshow(X[0][1]) \n",
    "        #         plt.show()\n",
    "            outputs = np.squeeze(model(X).cpu().clone().numpy())\n",
    "            test_result[:, :, i] = outputs\n",
    "            i += 1\n",
    "\n",
    "        img_output = nib.Nifti1Image(test_result, taimg.affine)\n",
    "        img_output.get_data_dtype() == np.dtype(np.int16)\n",
    "        nib.save(img_output, os.path.join(test_dir, subname, 'ML_result.nii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'd:/xhou4/ML_CVR/smooth8/ML_data/Unet_train_model_norm_135sub.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_py3_xh",
   "language": "python",
   "name": "py3_xh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
